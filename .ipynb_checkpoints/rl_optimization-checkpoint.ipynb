{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9706785c-9ae1-49c1-bfd2-24957bfb6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## required libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff065c3-7f9c-46a2-9811-48985c578263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import logging\n",
    "from entmax import sparsemax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce8f75e-2640-4bb3-aac9-51a399e5e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "# Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e601598-9124-4a67-aacf-9930847eef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.basicConfig(filename='outliers.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9179f978-e2b3-4d38-9e74-7919695de677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "545d9483-d5d2-4230-8cdc-e71b5b71a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_paths, seq_len=10, date_column='Date', feature_columns=['Open', 'Close', 'High', 'Low']):\n",
    "    dfs = []\n",
    "    for file in file_paths:\n",
    "        df = pd.read_excel(file)\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "        required_columns = [date_column.lower()] + [col.lower() for col in feature_columns]\n",
    "\n",
    "        def convert_date(date):\n",
    "            if isinstance(date, (int, float)):\n",
    "                base_date = datetime(1899, 12, 30)\n",
    "                return pd.to_datetime(base_date + timedelta(days=date))\n",
    "            elif isinstance(date, pd.Timestamp):\n",
    "                return date\n",
    "            else:\n",
    "                return pd.to_datetime(date, errors='coerce')\n",
    "\n",
    "        df['date'] = df['date'].apply(convert_date)\n",
    "        df = df.set_index('date')\n",
    "\n",
    "        for col in feature_columns:\n",
    "            df[col.lower()] = df[col.lower()].round(2)\n",
    "\n",
    "        if 'volume' in df.columns:\n",
    "            df = df[df['volume'] != 0]\n",
    "            df = df.drop(columns=['volume'])\n",
    "\n",
    "        df = df[required_columns[1:]].dropna()\n",
    "        dfs.append(df)\n",
    "\n",
    "    common_dates = pd.concat([df[['close']] for df in dfs], axis=1).dropna().index\n",
    "    dfs = [df.loc[common_dates] for df in dfs]\n",
    "\n",
    "    data = np.stack([df[[col.lower() for col in feature_columns]].values for df in dfs], axis=1)\n",
    "    sequences = [data[i:i + seq_len] for i in range(len(data) - seq_len + 1)]\n",
    "    sequences = torch.tensor(np.array(sequences), dtype=torch.float32).to(device)\n",
    "    print(f\"Final sequence tensor shape: {sequences.shape}\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a99e1a00-1454-4bed-acde-37ff02c2f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilated Causal Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d846c6f0-bb91-4de8-be0c-11a950d8cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(DCC, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              padding=(kernel_size - 1) * dilation, dilation=dilation)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        padding = (self.kernel_size - 1) * self.dilation\n",
    "        x = x[:, :, :-padding] if padding > 0 else x\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e3ddc9-e132-4aeb-8e50-bd39bdab585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5049882b-8590-4591-b42e-075d4914e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.1):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.Wg = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.Wa = nn.Linear(2 * in_features, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, node_features, edge_info):\n",
    "        batch_size, num_nodes, in_features = node_features.size()\n",
    "        h = self.Wg(node_features)\n",
    "\n",
    "        attention = torch.zeros(batch_size, num_nodes, num_nodes, device=node_features.device)\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(num_nodes):\n",
    "                concat_features = torch.cat([node_features[:, i, :], node_features[:, j, :]], dim=-1)\n",
    "                gate = torch.tanh(self.Wa(concat_features))\n",
    "                attention[:, i, j] = edge_info[:, i, j] * gate.squeeze()\n",
    "\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        attention = self.dropout(attention)\n",
    "\n",
    "        h_prime = torch.bmm(attention, h)\n",
    "        return F.elu(h_prime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baf5ea33-6594-4c80-9999-5585c0990c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6472b06a-b2a7-4ba5-8c9d-076a1a455fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioOptimization(nn.Module):\n",
    "    def __init__(self, num_assets, num_features=4, hidden_dim=64, input_seq_len=9):\n",
    "        super(PortfolioOptimization, self).__init__()\n",
    "        self.num_assets = num_assets\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_seq_len = input_seq_len\n",
    "        \n",
    "        self.dcc1 = DCC(num_features, hidden_dim, kernel_size=3, dilation=1)\n",
    "        self.dcc2 = DCC(hidden_dim, hidden_dim, kernel_size=3, dilation=2)\n",
    "        self.dcc3 = DCC(hidden_dim, hidden_dim, kernel_size=3, dilation=4)\n",
    "\n",
    "        self.Wq = nn.Linear(num_features * input_seq_len, hidden_dim)\n",
    "        self.Wk = nn.Linear(num_features * input_seq_len, hidden_dim)\n",
    "        self.Wv = nn.Linear(num_features * input_seq_len, hidden_dim)\n",
    "\n",
    "        self.gat = GATLayer(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.Wr = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.We = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.dcc_pred = DCC(hidden_dim * 3, num_features, kernel_size=3, dilation=1)\n",
    "\n",
    "        self.Wf = nn.Linear(hidden_dim * 3, hidden_dim)\n",
    "        self.conv_policy = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=1)\n",
    "        self.Wt = nn.Linear(hidden_dim + num_features, hidden_dim)\n",
    "        self.Ww = nn.Linear(hidden_dim, num_assets)\n",
    "\n",
    "\n",
    "        self.temperature = nn.Parameter(torch.tensor(.5))  # Learnable scalar\n",
    "\n",
    "\n",
    "    def forward(self, x, prev_weights=None):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        batch_size, seq_len, num_assets, num_features = x.size()\n",
    "\n",
    "        x_reshaped = x.permute(0, 2, 3, 1).reshape(batch_size * num_assets, num_features, seq_len)\n",
    "        fe = self.dcc1(x_reshaped)\n",
    "        fe = self.dcc2(fe)\n",
    "        fe = self.dcc3(fe)\n",
    "        fe = fe[:, :, -1].reshape(batch_size, num_assets, self.hidden_dim)\n",
    "\n",
    "        patches_flat = x.reshape(batch_size, num_assets, -1)\n",
    "        q = self.Wq(patches_flat)\n",
    "        k = self.Wk(patches_flat)\n",
    "        v = self.Wv(patches_flat)\n",
    "        attention = torch.bmm(q, k.transpose(1, 2)) / (self.hidden_dim ** 0.5)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        fr = self.gat(fe, attention)\n",
    "\n",
    "        fm = self.Wr(fr) + self.We(fe)\n",
    "        fm = fm.mean(dim=1, keepdim=True).expand(-1, num_assets, -1)\n",
    "\n",
    "        f = torch.cat([fe, fr, fm], dim=-1)\n",
    "        f_reshaped = f.permute(0, 2, 1)\n",
    "        x_pred = self.dcc_pred(f_reshaped)\n",
    "        x_pred = x_pred.permute(0, 2, 1)\n",
    "\n",
    "        f_policy = F.relu(self.conv_policy(self.Wf(f).permute(0, 2, 1))).permute(0, 2, 1)\n",
    "        f_policy = self.Wt(torch.cat([f_policy, x_pred], dim=-1))\n",
    "        \n",
    "        if prev_weights is not None:\n",
    "            f_policy = f_policy + prev_weights.unsqueeze(-1)\n",
    "        \n",
    "        # Select last time step for weight generation\n",
    "        raw_weights = self.Ww(f_policy[:, -1]) / self.temperature\n",
    "        raw_scores = self.Ww(f_policy[:, -1])  # [batch_size, num_assets]\n",
    "\n",
    "        # weights = F.softmax(raw_weights, dim=-1)\n",
    "        # weights = 0.05 + 0.80 * weights  # 5% min, 95% max per asset\n",
    "        weights = F.softmax(raw_weights / (self.temperature + 1e-8), dim=-1)  # Add temperature\n",
    "        weights = 0.10 + 0.60 * weights  # New: 10% min, 70% max (tighter bounds)\n",
    "        weights = weights / torch.sum(weights, dim=-1, keepdim=True)  # Renormalize\n",
    "\n",
    "        \n",
    "        return x_pred, weights\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Loss Functions\n",
    "# ------------------------\n",
    "def prediction_loss(pred, target):\n",
    "    return F.mse_loss(pred, target)\n",
    "\n",
    "def transaction_cost(prev_weights, new_weights, cost_rate=0.009):\n",
    "    if prev_weights is None:\n",
    "        return torch.zeros(new_weights.size(0), device=new_weights.device)\n",
    "    return cost_rate * torch.sum(torch.abs(new_weights - prev_weights), dim=-1)\n",
    "def entropy_loss(weights):\n",
    "    return -torch.sum((weights+ 1e-6) * torch.log(weights + 1e-8), dim=-1)  # per sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4ad202f-411a-499a-871a-d05b65921767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59555749-3524-43e5-a460-5d1435648cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, sequences, num_epochs=15, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    prev_weights = None\n",
    "    for epoch in range(num_epochs):\n",
    "        total_pred_loss = 0\n",
    "        total_reward = 0\n",
    "        for batch in sequences:\n",
    "            x_input = batch[:-1].unsqueeze(0)\n",
    "            target = batch[1:].unsqueeze(0)[:, -1]\n",
    "\n",
    "            x_pred, weights = model(x_input, prev_weights)\n",
    "            pred_loss = prediction_loss(x_pred, target)\n",
    "\n",
    "            relative_prices = target[:, :, 1] / batch[-2, :, 1]\n",
    "            portfolio_return = torch.sum(relative_prices * weights.squeeze(1), dim=-1)\n",
    "            transaction_costs = transaction_cost(prev_weights, weights.squeeze(1), cost_rate=0.0003)\n",
    "            u_t = 1 - transaction_costs\n",
    "            log_return = torch.log(u_t * portfolio_return + 1e-8)\n",
    "            entropy = entropy_loss(weights.squeeze(1))\n",
    "\n",
    "\n",
    "            lambda_entropy = 100 # tune this value\n",
    "            portfolio_variance = torch.var(relative_prices * weights.squeeze(1))\n",
    "            lambda_variance = 0.6  # Risk-return tradeoff\n",
    "\n",
    "            hhi_penalty = torch.sum(weights**2)  # Measures concentration\n",
    "            lambda_hhi = 1.0  # Strength of HHI penalty\n",
    "\n",
    "            rl_loss = (-torch.mean(log_return) + lambda_entropy * torch.mean(entropy) \n",
    "                       + lambda_variance * portfolio_variance+ lambda_hhi * hhi_penalty)  # New penalty\n",
    "            #rl_loss = -torch.mean(log_return) + lambda_entropy * torch.mean(entropy) + lambda_variance * portfolio_variance            \n",
    "            \n",
    "            lambda_pred = 0.1  # Prediction loss weight\n",
    "            loss = lambda_pred * pred_loss + rl_loss  # Focus on returns/risk\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_pred_loss += pred_loss.item()\n",
    "            total_reward += log_return.mean().item()\n",
    "            prev_weights = weights.detach().squeeze(1)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Pred Loss: {total_pred_loss / len(sequences):.4f}, Avg Return: {total_reward / len(sequences):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f65ad24-f8fc-4a7c-849f-8cd03f484f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b96b58ee-20d5-47a9-9a66-1ab8007ba1f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sequence tensor shape: torch.Size([831, 10, 6, 4])\n",
      "Epoch 1, Pred Loss: 7828.3176, Avg Return: 0.0018\n",
      "Epoch 2, Pred Loss: 7738.6075, Avg Return: 0.0018\n",
      "Epoch 3, Pred Loss: 7733.0211, Avg Return: 0.0018\n",
      "Epoch 4, Pred Loss: 7733.7358, Avg Return: 0.0018\n",
      "Epoch 5, Pred Loss: 7729.0688, Avg Return: 0.0018\n",
      "Predicted Prices (Open, Close, High, Low): [[[165.38034    0.       168.20473  164.30557 ]\n",
      "  [179.40688    0.       183.73047  178.32265 ]\n",
      "  [ 36.527283   0.        39.276367  37.80002 ]\n",
      "  [116.40097    0.       119.67396  116.74182 ]\n",
      "  [ 26.487701   0.        28.22962   27.306604]\n",
      "  [ 66.38871    0.        68.580635  67.022   ]]]\n",
      "Portfolio Weights: [0.08333332 0.08333332 0.08333332 0.08333332 0.5833333  0.08333332]\n",
      "Model saved to rl_portfolio_optimization.pth\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file_paths = [\n",
    "        r'training/bpcl1100d.xlsx',\n",
    "        r'training/hindpetro1100d.xlsx',\n",
    "        r'training/nmdc1100d.xlsx',\n",
    "        r'training/ongc1100d.xlsx',\n",
    "        r'training/irfc1100d.xlsx',\n",
    "        r'training/ioc1100d.xlsx',\n",
    "\n",
    "    ]\n",
    "    seq_len = 10\n",
    "    sequences = load_and_preprocess_data(file_paths, seq_len=seq_len)\n",
    "\n",
    "    num_assets = len(file_paths)\n",
    "    model = PortfolioOptimization(num_assets=num_assets, num_features=4, hidden_dim=128, input_seq_len=seq_len - 1).to(device)\n",
    "    train_model(model, sequences, num_epochs=5)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_input = sequences[0:1, :-1]\n",
    "        x_pred, weights = model(test_input)\n",
    "        print(\"Predicted Prices (Open, Close, High, Low):\", x_pred.cpu().numpy())\n",
    "        print(\"Portfolio Weights:\", weights[0].cpu().numpy())\n",
    "    torch.save(model.state_dict(), 'rl_portfolio_optimization.pth')\n",
    "    print(\"Model saved to rl_portfolio_optimization.pth\")\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de988a6-d123-4288-b88d-fc6dd941c89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ae81f-baf9-465c-939f-f63f476fc79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2edc0-238f-4f53-a992-ceafe2fed46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "010a2bad-6ef2-48a8-98f6-4e638dc82779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sequence tensor shape: torch.Size([831, 10, 5, 4])\n",
      "Epoch 1, Loss: 20.0268, Return: 1.0012, Pred Loss: 200.2791\n",
      "Epoch 2, Loss: 8.5020, Return: 1.0012, Pred Loss: 85.0305\n",
      "Epoch 3, Loss: 7.9447, Return: 1.0013, Pred Loss: 79.4588\n",
      "Epoch 4, Loss: 8.2472, Return: 1.0013, Pred Loss: 82.4830\n",
      "Epoch 5, Loss: 8.3282, Return: 1.0013, Pred Loss: 83.2936\n",
      "Predicted Prices: [[188.58778  189.73128  191.99306  187.52914 ]\n",
      " [ 45.407887  45.283485  45.406166  45.41267 ]\n",
      " [126.42849  126.88731  128.71248  125.734604]\n",
      " [ 34.13533   34.83085   35.84842   33.88716 ]\n",
      " [ 76.29765   76.8075    78.13028   75.876015]]\n",
      "Portfolio Weights: [0.6735402  0.07463504 0.06970803 0.08284672 0.09927008]\n",
      "Model saved to rl_portfolio_optimization.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4433cdd-5f29-464e-a022-bad44b6058a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535aeb6-6782-43c1-90fe-3207da4e33b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df8501-8665-4c8b-aff0-b2224aaf9a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
