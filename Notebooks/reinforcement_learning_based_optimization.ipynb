{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e683c629-b170-4876-97ae-63f2ddd0d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7cd99a-00a1-4cd4-b97c-2915c71592a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsarkar/.local/lib/python3.12/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import logging\n",
    "from entmax import sparsemax  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2775d1f0-6209-4e2a-86f5-1a0b3e1c2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3791b80d-cfbe-4075-a6ef-f2d4680c9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.basicConfig(filename='portfolio_optimization.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bed711b-0db2-41a0-907b-d8575ab99283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f796fd-4949-4cba-b58d-591daaba7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_paths, seq_len=10, date_column='Date', feature_columns=['Open', 'Close', 'High', 'Low']):\n",
    "    dfs = []\n",
    "    for file in file_paths:\n",
    "        df = pd.read_excel(file)\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "        required_columns = [date_column.lower()] + [col.lower() for col in feature_columns]\n",
    "\n",
    "        def convert_date(date):\n",
    "            if isinstance(date, (int, float)):\n",
    "                base_date = datetime(1899, 12, 30)\n",
    "                return pd.to_datetime(base_date + timedelta(days=date))\n",
    "            elif isinstance(date, pd.Timestamp):\n",
    "                return date\n",
    "            else:\n",
    "                return pd.to_datetime(date, errors='coerce')\n",
    "\n",
    "        df['date'] = df['date'].apply(convert_date)\n",
    "        df = df.set_index('date')\n",
    "\n",
    "        for col in feature_columns:\n",
    "            df[col.lower()] = df[col.lower()].round(2)\n",
    "\n",
    "        if 'volume' in df.columns:\n",
    "            df = df[df['volume'] != 0]\n",
    "            df = df.drop(columns=['volume'])\n",
    "\n",
    "        df = df[required_columns[1:]].dropna()\n",
    "        dfs.append(df)\n",
    "\n",
    "    common_dates = pd.concat([df[['close']] for df in dfs], axis=1).dropna().index\n",
    "    dfs = [df.loc[common_dates] for df in dfs]\n",
    "\n",
    "    data = np.stack([df[[col.lower() for col in feature_columns]].values for df in dfs], axis=1)\n",
    "    sequences = [data[i:i + seq_len] for i in range(len(data) - seq_len + 1)]\n",
    "    sequences = torch.tensor(np.array(sequences), dtype=torch.float32).to(device)\n",
    "    print(f\"Final sequence tensor shape: {sequences.shape}\")\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0930a5c4-c68c-4fe9-87c2-e1cc21d00626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilated Causal Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54703633-c6e0-4cb6-980f-48ccc49ce55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(DCC, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              padding=(kernel_size - 1) * dilation, dilation=dilation)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        padding = (self.kernel_size - 1) * self.dilation\n",
    "        x = x[:, :, :-padding] if padding > 0 else x\n",
    "        return F.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fea79a0-73f9-4560-91f9-5c0e09958fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d08201-bb71-4104-8508-e04a18384f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.1):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.Wg = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.Wa = nn.Linear(2 * in_features, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, node_features, edge_info):\n",
    "        batch_size, num_nodes, in_features = node_features.size()\n",
    "        h = self.Wg(node_features)\n",
    "\n",
    "        attention = torch.zeros(batch_size, num_nodes, num_nodes, device=node_features.device)\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(num_nodes):\n",
    "                concat_features = torch.cat([node_features[:, i, :], node_features[:, j, :]], dim=-1)\n",
    "                gate = torch.tanh(self.Wa(concat_features))\n",
    "                attention[:, i, j] = edge_info[:, i, j] * gate.squeeze()\n",
    "\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        attention = self.dropout(attention)\n",
    "\n",
    "        h_prime = torch.bmm(attention, h)\n",
    "        return F.elu(h_prime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb768411-ffc6-4d85-ae34-26c527a9886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b01e58dd-6181-4131-9a0a-a20c27fdbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioOptimization(nn.Module):\n",
    "    def __init__(self, num_assets, num_features=4, hidden_dim=128, input_seq_len=10):\n",
    "        super(PortfolioOptimization, self).__init__()\n",
    "        self.num_assets = num_assets\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_seq_len = input_seq_len\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.dcc1 = DCC(num_features, hidden_dim, kernel_size=3, dilation=1)\n",
    "        self.dcc2 = DCC(hidden_dim, hidden_dim, kernel_size=3, dilation=2)\n",
    "        self.dcc3 = DCC(hidden_dim, hidden_dim, kernel_size=3, dilation=4)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.Wq = nn.Linear(num_features * input_seq_len, hidden_dim)\n",
    "        self.Wk = nn.Linear(num_features * input_seq_len, hidden_dim)\n",
    "        self.Wv = nn.Linear(num_features * input_seq_len, hidden_dim)\n",
    "\n",
    "        # self.Wq = nn.Linear(40, hidden_dim)\n",
    "        # self.Wk = nn.Linear(40, hidden_dim)\n",
    "        # self.Wv = nn.Linear(40, hidden_dim)\n",
    "\n",
    "        # Graph attention\n",
    "        self.gat = GATLayer(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Feature combination\n",
    "        self.Wr = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.We = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Prediction head\n",
    "        self.dcc_pred = DCC(hidden_dim * 3, num_features, kernel_size=3, dilation=1)\n",
    "\n",
    "        # Policy head\n",
    "        self.Wf = nn.Linear(hidden_dim * 3, hidden_dim)\n",
    "        self.conv_policy = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=1)\n",
    "        self.Wt = nn.Linear(hidden_dim + num_features, hidden_dim)\n",
    "        self.Ww = nn.Linear(hidden_dim, num_assets)\n",
    "\n",
    "        # Allocation parameters\n",
    "        self.min_weight = 0.05\n",
    "        self.rank_power = 1.0\n",
    "        self.temperature = nn.Parameter(torch.tensor(1.0))  # Learnable temperature\n",
    "        self.price_scale = nn.Parameter(torch.ones(num_features))\n",
    "        self.price_bias = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, x, prev_weights=None):\n",
    "       \n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        batch_size, seq_len, num_assets, num_features = x.size()\n",
    "    \n",
    "        # Feature extraction\n",
    "        x_reshaped = x.permute(0, 2, 3, 1).reshape(batch_size * num_assets, num_features, seq_len)\n",
    "        fe = self.dcc1(x_reshaped)\n",
    "        fe = self.dcc2(fe)\n",
    "        fe = self.dcc3(fe)\n",
    "        fe = fe[:, :, -1].reshape(batch_size, num_assets, self.hidden_dim)\n",
    "    \n",
    "        # Cross-asset attention\n",
    "        patches_flat = x.reshape(batch_size, num_assets, -1)\n",
    "        q = self.Wq(patches_flat)\n",
    "        k = self.Wk(patches_flat)\n",
    "        v = self.Wv(patches_flat)\n",
    "        attention = torch.bmm(q, k.transpose(1, 2)) / (self.hidden_dim ** 0.5)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "    \n",
    "        # Graph attention\n",
    "        fr = self.gat(fe, attention)\n",
    "    \n",
    "        # Market context\n",
    "        fm = self.Wr(fr) + self.We(fe)\n",
    "        fm = fm.mean(dim=1, keepdim=True).expand(-1, num_assets, -1)\n",
    "    \n",
    "        # Combined features\n",
    "        f = torch.cat([fe, fr, fm], dim=-1)\n",
    "        f_reshaped = f.permute(0, 2, 1)\n",
    "        x_pred = self.dcc_pred(f_reshaped)\n",
    "        x_pred = x_pred.permute(0, 2, 1)\n",
    "        \n",
    "        # Ensure positive predictions using modified softplus\n",
    "        x_pred = F.softplus(x_pred) * 1.5  # Scale to prevent predictions from being too small\n",
    "    \n",
    "        # Policy features\n",
    "        f_policy = F.relu(self.conv_policy(self.Wf(f).permute(0, 2, 1))).permute(0, 2, 1)\n",
    "        f_policy = self.Wt(torch.cat([f_policy, x_pred], dim=-1))\n",
    "        \n",
    "        if prev_weights is not None:\n",
    "            f_policy = f_policy + prev_weights.unsqueeze(-1)\n",
    "    \n",
    "        # Raw score for allocation\n",
    "        raw_scores = self.Ww(f_policy[:, -1])  # shape: [B, A]\n",
    "        \n",
    "        # Get predicted returns from the Close prices (index 1 in features)\n",
    "        predicted_returns = x_pred[:, :, 1]  # shape: [B, A]\n",
    "        \n",
    "        # Combine raw scores with predicted returns for ranking\n",
    "        combined_scores = raw_scores + predicted_returns.detach()  # Detach to prevent double counting\n",
    "        \n",
    "        # Create differentiable rank weights\n",
    "        ranks = torch.argsort(torch.argsort(combined_scores, dim=1, descending=True))\n",
    "        rank_weights = 1.0 / (ranks.float() + 1)  # 1/rank weighting\n",
    "        \n",
    "        # Normalize rank weights\n",
    "        rank_weights = rank_weights / rank_weights.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        # Apply temperature-scaled sparsemax to combined scores\n",
    "        scaled_scores = combined_scores / (self.temperature + 1e-8)\n",
    "        sparse_weights = sparsemax(scaled_scores, dim=-1)\n",
    "        \n",
    "        # Blend sparse weights with rank weights (adjust ratio as needed)\n",
    "        weights = 0.7 * sparse_weights + 0.3 * rank_weights\n",
    "        \n",
    "        # Apply min allocation constraint and normalize\n",
    "        weights = self.min_weight + (1.0 - self.min_weight * num_assets) * weights\n",
    "        weights = weights / weights.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        return x_pred, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c3766c-d518-4962-8e6a-f77b2f13ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871cd617-c1f4-4803-a88a-78a933e52ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, sequences, num_epochs=15, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    prev_weights = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_return = 0\n",
    "        total_pred_loss = 0\n",
    "\n",
    "        for batch in sequences:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x_input = batch[:-1].unsqueeze(0)\n",
    "            target = batch[1:].unsqueeze(0)[:, -1]\n",
    "\n",
    "            x_pred, weights = model(x_input, prev_weights)\n",
    "\n",
    "            # Price prediction loss\n",
    "            pred_loss = F.mse_loss(x_pred, target)\n",
    "            \n",
    "            # Return calculation\n",
    "            with torch.no_grad():\n",
    "                price_ratios = target[:, :, 1] / batch[-2, :, 1]  # Close-to-close returns\n",
    "            \n",
    "            portfolio_return = torch.sum(price_ratios * weights, dim=-1)\n",
    "            \n",
    "            # Transaction costs\n",
    "            if prev_weights is not None:\n",
    "                with torch.no_grad():\n",
    "                    turnover = torch.sum(torch.abs(weights - prev_weights), dim=-1)\n",
    "                    transaction_costs = 0.0003 * turnover\n",
    "                net_return = portfolio_return - transaction_costs\n",
    "            else:\n",
    "                net_return = portfolio_return\n",
    "            \n",
    "            # Combined loss\n",
    "            return_loss = -torch.mean(torch.log(net_return + 1e-6))\n",
    "            loss = return_loss + 0.1 * pred_loss  # Weighted combination\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_return += torch.mean(net_return).item()\n",
    "            total_pred_loss += pred_loss.item()\n",
    "            prev_weights = weights.detach()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(sequences):.4f}, \"\n",
    "              f\"Return: {total_return/len(sequences):.4f}, \"\n",
    "              f\"Pred Loss: {total_pred_loss/len(sequences):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05e5c0ed-ea75-4235-a6cf-a64eb978fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a14197a9-1242-447f-9d4f-b8e71d0b9d8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sequence tensor shape: torch.Size([831, 10, 6, 4])\n",
      "Epoch 1, Loss: 20.2638, Return: 1.0011, Pred Loss: 202.6473\n",
      "Epoch 2, Loss: 9.6422, Return: 1.0013, Pred Loss: 96.4324\n",
      "Epoch 3, Loss: 9.5388, Return: 1.0013, Pred Loss: 95.3987\n",
      "Epoch 4, Loss: 9.2297, Return: 1.0008, Pred Loss: 92.3035\n",
      "Epoch 5, Loss: 9.0691, Return: 1.0012, Pred Loss: 90.7016\n",
      "Epoch 6, Loss: 9.7815, Return: 1.0012, Pred Loss: 97.8250\n",
      "Epoch 7, Loss: 9.3539, Return: 1.0012, Pred Loss: 93.5497\n",
      "Epoch 8, Loss: 8.8136, Return: 1.0012, Pred Loss: 88.1459\n",
      "Epoch 9, Loss: 8.8007, Return: 1.0012, Pred Loss: 88.0175\n",
      "Epoch 10, Loss: 7.7312, Return: 1.0012, Pred Loss: 77.3225\n",
      "Epoch 11, Loss: 7.5322, Return: 1.0012, Pred Loss: 75.3325\n",
      "Epoch 12, Loss: 6.6497, Return: 1.0012, Pred Loss: 66.5077\n",
      "Epoch 13, Loss: 6.5890, Return: 1.0012, Pred Loss: 65.9005\n",
      "Epoch 14, Loss: 6.2388, Return: 1.0012, Pred Loss: 62.3981\n",
      "Epoch 15, Loss: 6.5636, Return: 1.0012, Pred Loss: 65.6467\n",
      "Epoch 16, Loss: 5.6047, Return: 1.0012, Pred Loss: 56.0575\n",
      "Epoch 17, Loss: 5.6594, Return: 1.0012, Pred Loss: 56.6047\n",
      "Epoch 18, Loss: 5.4120, Return: 1.0012, Pred Loss: 54.1299\n",
      "Epoch 19, Loss: 4.9517, Return: 1.0012, Pred Loss: 49.5271\n",
      "Epoch 20, Loss: 4.6626, Return: 1.0012, Pred Loss: 46.6364\n",
      "Epoch 21, Loss: 4.4693, Return: 1.0012, Pred Loss: 44.7031\n",
      "Epoch 22, Loss: 4.1617, Return: 1.0012, Pred Loss: 41.6272\n",
      "Epoch 23, Loss: 4.3365, Return: 1.0012, Pred Loss: 43.3753\n",
      "Epoch 24, Loss: 3.9703, Return: 1.0012, Pred Loss: 39.7130\n",
      "Epoch 25, Loss: 3.9172, Return: 1.0012, Pred Loss: 39.1827\n",
      "Epoch 26, Loss: 3.9315, Return: 1.0012, Pred Loss: 39.3257\n",
      "Epoch 27, Loss: 3.9453, Return: 1.0012, Pred Loss: 39.4636\n",
      "Epoch 28, Loss: 3.8820, Return: 1.0012, Pred Loss: 38.8303\n",
      "Epoch 29, Loss: 3.7737, Return: 1.0012, Pred Loss: 37.7469\n",
      "Epoch 30, Loss: 3.8832, Return: 1.0012, Pred Loss: 38.8421\n",
      "Epoch 31, Loss: 3.8178, Return: 1.0012, Pred Loss: 38.1885\n",
      "Epoch 32, Loss: 3.6579, Return: 1.0012, Pred Loss: 36.5891\n",
      "Epoch 33, Loss: 3.7652, Return: 1.0012, Pred Loss: 37.6626\n",
      "Epoch 34, Loss: 3.8665, Return: 1.0012, Pred Loss: 38.6750\n",
      "Epoch 35, Loss: 3.7769, Return: 1.0012, Pred Loss: 37.7793\n",
      "Epoch 36, Loss: 3.6782, Return: 1.0012, Pred Loss: 36.7921\n",
      "Epoch 37, Loss: 3.6994, Return: 1.0012, Pred Loss: 37.0046\n",
      "Epoch 38, Loss: 3.5220, Return: 1.0012, Pred Loss: 35.2306\n",
      "Epoch 39, Loss: 3.6410, Return: 1.0012, Pred Loss: 36.4201\n",
      "Epoch 40, Loss: 3.4874, Return: 1.0012, Pred Loss: 34.8840\n",
      "Epoch 41, Loss: 3.5616, Return: 1.0012, Pred Loss: 35.6258\n",
      "Epoch 42, Loss: 3.3141, Return: 1.0012, Pred Loss: 33.1512\n",
      "Epoch 43, Loss: 3.4498, Return: 1.0012, Pred Loss: 34.5084\n",
      "Epoch 44, Loss: 3.3474, Return: 1.0012, Pred Loss: 33.4843\n",
      "Epoch 45, Loss: 3.2539, Return: 1.0012, Pred Loss: 32.5493\n",
      "Epoch 46, Loss: 3.1814, Return: 1.0012, Pred Loss: 31.8241\n",
      "Epoch 47, Loss: 3.0377, Return: 1.0012, Pred Loss: 30.3871\n",
      "Epoch 48, Loss: 3.1258, Return: 1.0012, Pred Loss: 31.2687\n",
      "Epoch 49, Loss: 2.9667, Return: 1.0012, Pred Loss: 29.6773\n",
      "Epoch 50, Loss: 3.0005, Return: 1.0012, Pred Loss: 30.0153\n",
      "Predicted Prices: [[129.34258  131.19106  132.25082  128.3264  ]\n",
      " [183.25848  185.94269  187.3818   181.65607 ]\n",
      " [200.93753  204.52155  206.01529  198.87769 ]\n",
      " [ 46.2947    50.084076  48.88047   46.999245]\n",
      " [ 31.97297   35.702995  34.597954  32.957504]\n",
      " [ 76.410866  80.12737   79.71673   77.038284]]\n",
      "Portfolio Weights: [0.6257143  0.09285714 0.07857143 0.06714286 0.06428572 0.07142857]\n",
      "Model saved to rl_portfolio_optimization50.pth\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file_paths = [\n",
    "        r'training/ongc1100d.xlsx',\n",
    "        r'training/bpcl1100d.xlsx',\n",
    "        r'training/hindpetro1100d.xlsx',\n",
    "        r'training/nmdc1100d.xlsx',\n",
    "        r'training/irfc1100d.xlsx',\n",
    "        r'training/ioc1100d.xlsx'\n",
    "    ]\n",
    "\n",
    "    seq_len = 10\n",
    "    sequences = load_and_preprocess_data(file_paths, seq_len=seq_len)\n",
    "    num_assets = len(file_paths)\n",
    "\n",
    "    model = PortfolioOptimization(num_assets=num_assets, num_features=4, hidden_dim=128, input_seq_len=seq_len-1).to(device)\n",
    "    #seq_len = 10\n",
    "    # sequences = load_and_preprocess_data(file_paths, seq_len=seq_len)\n",
    "    # model = PortfolioOptimization(num_assets=len(file_paths), input_seq_len=seq_len).to(device)\n",
    "    train_model(model, sequences, num_epochs=50)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_input = sequences[0:1, :-1]\n",
    "        x_pred, weights = model(test_input)\n",
    "        print(\"Predicted Prices:\", x_pred[0].cpu().numpy())\n",
    "        print(\"Portfolio Weights:\", weights[0].cpu().numpy())\n",
    "\n",
    "    torch.save(model.state_dict(), 'rl_portfolio_optimization50.pth')\n",
    "    print(\"Model saved to rl_portfolio_optimization50.pth\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2eb43b-66a3-4925-b500-ff0688f087f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d6ce3-b010-49ef-b503-f6eb130d7da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02538389-4a87-4615-a10b-34a99bc187c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6e117-cc69-4270-99a5-0f78234513b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd17f06-357c-49c8-ab38-8c11a3689a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
