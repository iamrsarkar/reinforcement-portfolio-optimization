{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e5aca-d186-4e84-93fd-f496701add48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA DOWNLOAD ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9357a2c-6c67-47e5-b6fe-0141f167c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ronu\\AppData\\Local\\Temp\\ipykernel_18180\\3632997598.py:19: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start_str, end=end_str, interval=\"1d\")\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# List of stock symbols\n",
    "stock_list = [\"ioc\"]#, \"hindpetro\", \"bpcl\", \"ongc\",\"nmdc\",\"irfc\"]\n",
    "\n",
    "# Compute the date range\n",
    "end_date = datetime.today() - timedelta(days=0)\n",
    "start_date = datetime.today() - timedelta(days=200)\n",
    "\n",
    "# Format dates as strings (yyyy-mm-dd)\n",
    "start_str = start_date.strftime('%Y-%m-%d')\n",
    "end_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Download data\n",
    "for stock in stock_list:\n",
    "    ticker = f\"{stock}.NS\"\n",
    "    data = yf.download(ticker, start=start_str, end=end_str, interval=\"1d\")\n",
    "    data.to_excel(f\"testing/{stock}20u0d.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650355a-8b10-4d64-a8c8-e893f6c41269",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING HTE DATA LEN##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa7e19cd-b576-44b6-8c9f-64bf5daae0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "902\n",
      "902\n",
      "902\n",
      "902\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for i in list:\n",
    "    df=pd.read_excel(f\"training\\\\{i}940d.xlsx\")\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32449543-bed8-4253-b7db-6d4617878431",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DELETING THE RECENT 40 DAYS DATA, WILL BE USED FOR TESTING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d8f980b-170d-46d3-9dcf-d9294ed73e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\\irfc940d.xlsx: trimmed and saved.\n",
      "training\\ioc940d.xlsx: trimmed and saved.\n",
      "training\\hindpetro940d.xlsx: trimmed and saved.\n",
      "training\\bpcl940d.xlsx: trimmed and saved.\n",
      "training\\rvnl940d.xlsx: trimmed and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List of base filenames (without extension and path)\n",
    "companies = [\"irfc\", \"ioc\", \"hindpetro\", \"bpcl\", \"rvnl\"]\n",
    "\n",
    "for i in companies:\n",
    "    file_path = f\"training\\\\{i}940d.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        # Read Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Drop the last 40 rows\n",
    "        df_trimmed = df[:-40]  # or df.iloc[:-40]\n",
    "\n",
    "        # Save back to the same file (or a new one if you want to keep the original)\n",
    "        df_trimmed.to_excel(file_path, index=False)\n",
    "        print(f\"{file_path}: trimmed and saved.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0daa90ba-d4fc-4626-b68e-60b8aeacf712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in training\\irfc900d.xlsx: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "Columns in training\\ioc900d.xlsx: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "Columns in training\\hindpetro900d.xlsx: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_paths = [r'training\\irfc900d.xlsx', r'training\\ioc900d.xlsx', r'training\\hindpetro900d.xlsx']\n",
    "for file in file_paths:\n",
    "    df = pd.read_excel(file)\n",
    "    print(f\"Columns in {file}: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "967535a6-53d1-43d1-b158-160fd960fcf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'training\\csv\\hindpetro900d.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Set up logging for outliers\n",
    "logging.basicConfig(filename='outliers.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Define file paths\n",
    "input_file = r'training\\hindpetro900d.xlsx'\n",
    "output_file = r'training\\csv\\hindpetro900d.csv'\n",
    "\n",
    "# Check if input file exists\n",
    "if not os.path.exists(input_file):\n",
    "    raise FileNotFoundError(f\"Input file '{input_file}' not found. Please verify the file path.\")\n",
    "\n",
    "# Read the Excel file\n",
    "try:\n",
    "    df = pd.read_excel(input_file)\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error loading '{input_file}': {str(e)}\")\n",
    "\n",
    "# Standardize column names (handle case sensitivity, spaces, etc.)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Check for required columns\n",
    "required_columns = ['date', 'open', 'close', 'high', 'low']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing required columns: {missing_columns}. Found columns: {list(df.columns)}\")\n",
    "\n",
    "# Function to convert Excel serial date or Timestamp to YYYY-MM-DD\n",
    "def convert_date(date):\n",
    "    if isinstance(date, (int, float)):  # Excel serial date\n",
    "        base_date = datetime(1899, 12, 30)  # Excel's base date\n",
    "        return (base_date + timedelta(days=date)).strftime('%Y-%m-%d')\n",
    "    elif isinstance(date, pd.Timestamp):  # Already a Timestamp\n",
    "        return date.strftime('%Y-%m-%d')\n",
    "    else:  # Fallback for unexpected types\n",
    "        return str(date)\n",
    "\n",
    "# 1. Convert Date column to YYYY-MM-DD\n",
    "df['date'] = df['date'].apply(convert_date)\n",
    "\n",
    "# 2. Round price columns to 2 decimal places\n",
    "price_columns = ['close', 'high', 'low', 'open']\n",
    "for col in price_columns:\n",
    "    df[col] = df[col].round(2)\n",
    "\n",
    "# 3. Flag potential outliers (price changes > 20% day-to-day)\n",
    "for i in range(1, len(df)):\n",
    "    prev_close = df.loc[i-1, 'close']\n",
    "    curr_close = df.loc[i, 'close']\n",
    "    if prev_close != 0:\n",
    "        pct_change = abs((curr_close - prev_close) / prev_close * 100)\n",
    "        if pct_change > 20:\n",
    "            logging.info(f\"Potential outlier on {df.loc[i, 'date']}: Close price changed from {prev_close} to {curr_close} ({pct_change:.2f}%)\")\n",
    "\n",
    "# 4. Remove rows with zero volume (if Volume column exists)\n",
    "if 'volume' in df.columns:\n",
    "    df = df[df['volume'] != 0]\n",
    "    # 5. Drop the Volume column\n",
    "    df = df.drop(columns=['volume'])\n",
    "else:\n",
    "    print(\"Warning: 'volume' column not found, skipping zero-volume removal and drop.\")\n",
    "\n",
    "# 6. Exclude the last row if it's incomplete (check for NaN in required columns)\n",
    "if df[required_columns].iloc[-1].isna().any():\n",
    "    df = df.iloc[:-1]\n",
    "\n",
    "# 7. Ensure consistent data types (floats for prices)\n",
    "for col in price_columns:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# 8. Capitalize column names for output (Date, Open, Close, High, Low)\n",
    "df = df.rename(columns={'date': 'Date', 'open': 'Open', 'close': 'Close', 'high': 'High', 'low': 'Low'})\n",
    "\n",
    "# 9. Save to a clean CSV file\n",
    "try:\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Cleaned data saved to '{output_file}'\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error saving to '{output_file}': {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9606f4f-15f7-4691-a068-4e03dad8617f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
